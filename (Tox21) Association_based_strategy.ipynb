{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "dgBTU57OWYI0"
   },
   "source": [
    "# Install Library\n",
    "\n",
    "[RDKit ](https://github.com/rdkit/rdkit)\n",
    "\n",
    "[DGL](https://github.com/dmlc/dgl/)\n",
    "\n",
    "[DGL-LifeSci](https://github.com/awslabs/dgl-lifesci)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "id": "EOF1QxeqhajG"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install rdkit-pypi\n",
    "!pip install dgllife\n",
    "!pip install --pre dgl-cu113 dglgo -f https://data.dgl.ai/wheels-test/repo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "xtojkovzWYI2"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl \n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from dgllife.model import MLPPredictor\n",
    "from tensorflow.keras.callbacks import  History\n",
    "from dgllife.utils import smiles_to_bigraph, CanonicalAtomFeaturizer, AttentiveFPAtomFeaturizer\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Utils.general import DATASET, get_dataset, separate_active_and_inactive_data, get_embedding_vector_class, count_lablel,data_generator, up_and_down_Samplenig\n",
    "from Utils.gcnpretrained import get_tox21_model\n",
    "from Models.heterogeneous_siamese_tox21 import siamese_model_attentiveFp_tox21, siamese_model_Canonical_tox21\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "1RVgRpTmQ5rp",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\stdso\\.dgl/tox21.csv.gz from https://data.dgl.ai/dataset/tox21.csv.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdso\\.dgl/tox21.csv.gz: 123kB [00:00, 409kB/s] \n"
     ]
    }
   ],
   "source": [
    "cache_path='./tox21_dglgraph.bin'\n",
    "\n",
    "df = get_dataset(\"tox21\")\n",
    "id = df['mol_id']\n",
    "df = df.drop(columns=['mol_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "id": "m_nAHT_WhajK"
   },
   "outputs": [],
   "source": [
    "tox21_tasks = df.columns.values[:12].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "GEdp1FUphajL",
    "outputId": "352d95e6-5d5c-4c98-8d51-d7f330c51e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR-AR one: 309  zero: 6956  NAN: 566\n",
      "NR-AR-LBD one: 237  zero: 6521  NAN: 1073\n",
      "NR-AhR one: 768  zero: 5781  NAN: 1282\n",
      "NR-Aromatase one: 300  zero: 5521  NAN: 2010\n",
      "NR-ER one: 793  zero: 5400  NAN: 1638\n",
      "NR-ER-LBD one: 350  zero: 6605  NAN: 876\n",
      "NR-PPAR-gamma one: 186  zero: 6264  NAN: 1381\n",
      "SR-ARE one: 942  zero: 4890  NAN: 1999\n",
      "SR-ATAD5 one: 264  zero: 6808  NAN: 759\n",
      "SR-HSE one: 372  zero: 6095  NAN: 1364\n",
      "SR-MMP one: 918  zero: 4892  NAN: 2021\n",
      "SR-p53 one: 423  zero: 6351  NAN: 1057\n"
     ]
    }
   ],
   "source": [
    "one = []\n",
    "zero = []\n",
    "nan = []\n",
    " \n",
    "for task in tox21_tasks:\n",
    "    a = list(df[task].value_counts(dropna=False).to_dict().values())\n",
    "    zero.append(a[0])\n",
    "    nan.append(a[1])\n",
    "    one.append(a[2])\n",
    "    print(task ,\"one:\" ,a[2] ,\" zero:\", a[0], \" NAN:\",a[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5862, 72084)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(one), sum(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "hidden": true,
    "id": "QjNMCFSqhajM",
    "outputId": "112c0f92-1e31-467c-e3b5-a9285f9c9f14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the matplotlib library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Declaring the figure or the plot (y, x) or (width, height)\n",
    "plt.figure(figsize=[20, 15])\n",
    "\n",
    "X = np.arange(1,len(tox21_tasks)+1)\n",
    "plt.bar(X + 0.2, one, color = 'g', width = 0.25)\n",
    "plt.bar(X + 0.4, zero, color = 'b', width = 0.25)\n",
    "plt.bar(X + 0.6, nan, color = 'r', width = 0.25)\n",
    "\n",
    "# Creating the legend of the bars in the plot\n",
    "plt.legend(['Active' , 'Inactive' ,'NAN'])\n",
    "# Overiding the x axis with the country names\n",
    "plt.xticks([i + 0.25 for i in range(1,13)], X)\n",
    "# Giving the tilte for the plot\n",
    "plt.title(\"Tox21 dataset diagram\")\n",
    "# Namimg the x and y axis\n",
    "plt.xlabel('Tox21_tasks')\n",
    "plt.ylabel('Cases')\n",
    "# Saving the plot as a 'png'\n",
    "plt.savefig('4BarPlot.png')\n",
    "# Displaying the bar plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "6grIE_JeqkUZ"
   },
   "source": [
    "# Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "id": "IzllOg474i99"
   },
   "outputs": [],
   "source": [
    "from dgllife.model import MLPPredictor\n",
    "\n",
    "def create_dataset_with_gcn(dataset, class_embed_vector, GCN, tasks, numberTask):\n",
    "\n",
    "    created_data = []\n",
    "    data = np.arange(len(tasks))\n",
    "    onehot_encoded = to_categorical(data)\n",
    "\n",
    "    for i, data in enumerate(dataset):\n",
    "        smiles, g, label, mask = data\n",
    "        g = g.to(device)\n",
    "        g = dgl.add_self_loop(g)\n",
    "        graph_feats = g.ndata.pop('h')\n",
    "        embbed = GCN(g, graph_feats)\n",
    "        embbed = embbed.to('cpu')\n",
    "        embbed = embbed.detach().numpy()\n",
    "        a = ( embbed, onehot_encoded[numberTask], class_embed_vector[numberTask], label, numberTask, tasks[numberTask])\n",
    "        created_data.append(a)\n",
    "    print('Data created!!')\n",
    "    return created_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Calculation of embedded vectors for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR-AR=> positive: 309 - negative: 6956\n",
      "NR-AR-LBD=> positive: 237 - negative: 6521\n",
      "NR-AhR=> positive: 768 - negative: 5781\n",
      "NR-Aromatase=> positive: 300 - negative: 5521\n",
      "NR-ER=> positive: 793 - negative: 5400\n",
      "NR-ER-LBD=> positive: 350 - negative: 6605\n",
      "NR-PPAR-gamma=> positive: 186 - negative: 6264\n",
      "SR-ARE=> positive: 942 - negative: 4890\n",
      "SR-ATAD5=> positive: 264 - negative: 6808\n",
      "SR-HSE=> positive: 372 - negative: 6095\n",
      "SR-MMP=> positive: 918 - negative: 4892\n",
      "SR-p53=> positive: 423 - negative: 6351\n"
     ]
    }
   ],
   "source": [
    "df_positive, df_negative = separate_active_and_inactive_data(df, tox21_tasks)\n",
    "\n",
    "for i,d in enumerate(zip(df_positive,df_negative)):\n",
    "    print(f'{tox21_tasks[i]}=> positive: {len(d[0])} - negative: {len(d[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6956\n",
      "Processing molecule 2000/6956\n",
      "Processing molecule 3000/6956\n",
      "Processing molecule 4000/6956\n",
      "Processing molecule 5000/6956\n",
      "Processing molecule 6000/6956\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6521\n",
      "Processing molecule 2000/6521\n",
      "Processing molecule 3000/6521\n",
      "Processing molecule 4000/6521\n",
      "Processing molecule 5000/6521\n",
      "Processing molecule 6000/6521\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/5781\n",
      "Processing molecule 2000/5781\n",
      "Processing molecule 3000/5781\n",
      "Processing molecule 4000/5781\n",
      "Processing molecule 5000/5781\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/5521\n",
      "Processing molecule 2000/5521\n",
      "Processing molecule 3000/5521\n",
      "Processing molecule 4000/5521\n",
      "Processing molecule 5000/5521\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/5400\n",
      "Processing molecule 2000/5400\n",
      "Processing molecule 3000/5400\n",
      "Processing molecule 4000/5400\n",
      "Processing molecule 5000/5400\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6605\n",
      "Processing molecule 2000/6605\n",
      "Processing molecule 3000/6605\n",
      "Processing molecule 4000/6605\n",
      "Processing molecule 5000/6605\n",
      "Processing molecule 6000/6605\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6264\n",
      "Processing molecule 2000/6264\n",
      "Processing molecule 3000/6264\n",
      "Processing molecule 4000/6264\n",
      "Processing molecule 5000/6264\n",
      "Processing molecule 6000/6264\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/4890\n",
      "Processing molecule 2000/4890\n",
      "Processing molecule 3000/4890\n",
      "Processing molecule 4000/4890\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6808\n",
      "Processing molecule 2000/6808\n",
      "Processing molecule 3000/6808\n",
      "Processing molecule 4000/6808\n",
      "Processing molecule 5000/6808\n",
      "Processing molecule 6000/6808\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6095\n",
      "Processing molecule 2000/6095\n",
      "Processing molecule 3000/6095\n",
      "Processing molecule 4000/6095\n",
      "Processing molecule 5000/6095\n",
      "Processing molecule 6000/6095\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/4892\n",
      "Processing molecule 2000/4892\n",
      "Processing molecule 3000/4892\n",
      "Processing molecule 4000/4892\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6351\n",
      "Processing molecule 2000/6351\n",
      "Processing molecule 3000/6351\n",
      "Processing molecule 4000/6351\n",
      "Processing molecule 5000/6351\n",
      "Processing molecule 6000/6351\n"
     ]
    }
   ],
   "source": [
    "dataset_positive = [DATASET(d,smiles_to_bigraph, AttentiveFPAtomFeaturizer(), cache_file_path = cache_path) for d in df_positive]\n",
    "dataset_negative = [DATASET(d,smiles_to_bigraph, AttentiveFPAtomFeaturizer(), cache_file_path = cache_path) for d in df_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class vector created!!\n"
     ]
    }
   ],
   "source": [
    "embed_class_tox21 = get_embedding_vector_class(dataset_positive, dataset_negative, radius=2, size = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zIKQi__XAcia"
   },
   "source": [
    "# Classification with BioAct-Het and AttentiveFp GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "lDS5UguKr_x_",
    "outputId": "da58be7e-197e-4838-f5f1-a0b2d6b87cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GCN_attentivefp_Tox21_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gcn_attentivefp_tox21.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN_attentivefp_Tox21_pre_trained.pth: 100%|| 1.95M/1.95M [00:00<00:00, 2.11MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GCN_attentivefp_Tox21'\n",
    "gcn_model = get_tox21_model(model_name)\n",
    "gcn_model.eval()\n",
    "gcn_model = gcn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/7265\n",
      "Processing molecule 2000/7265\n",
      "Processing molecule 3000/7265\n",
      "Processing molecule 4000/7265\n",
      "Processing molecule 5000/7265\n",
      "Processing molecule 6000/7265\n",
      "Processing molecule 7000/7265\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6758\n",
      "Processing molecule 2000/6758\n",
      "Processing molecule 3000/6758\n",
      "Processing molecule 4000/6758\n",
      "Processing molecule 5000/6758\n",
      "Processing molecule 6000/6758\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6549\n",
      "Processing molecule 2000/6549\n",
      "Processing molecule 3000/6549\n",
      "Processing molecule 4000/6549\n",
      "Processing molecule 5000/6549\n",
      "Processing molecule 6000/6549\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/5821\n",
      "Processing molecule 2000/5821\n",
      "Processing molecule 3000/5821\n",
      "Processing molecule 4000/5821\n",
      "Processing molecule 5000/5821\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6193\n",
      "Processing molecule 2000/6193\n",
      "Processing molecule 3000/6193\n",
      "Processing molecule 4000/6193\n",
      "Processing molecule 5000/6193\n",
      "Processing molecule 6000/6193\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6955\n",
      "Processing molecule 2000/6955\n",
      "Processing molecule 3000/6955\n",
      "Processing molecule 4000/6955\n",
      "Processing molecule 5000/6955\n",
      "Processing molecule 6000/6955\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6450\n",
      "Processing molecule 2000/6450\n",
      "Processing molecule 3000/6450\n",
      "Processing molecule 4000/6450\n",
      "Processing molecule 5000/6450\n",
      "Processing molecule 6000/6450\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/5832\n",
      "Processing molecule 2000/5832\n",
      "Processing molecule 3000/5832\n",
      "Processing molecule 4000/5832\n",
      "Processing molecule 5000/5832\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/7072\n",
      "Processing molecule 2000/7072\n",
      "Processing molecule 3000/7072\n",
      "Processing molecule 4000/7072\n",
      "Processing molecule 5000/7072\n",
      "Processing molecule 6000/7072\n",
      "Processing molecule 7000/7072\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6467\n",
      "Processing molecule 2000/6467\n",
      "Processing molecule 3000/6467\n",
      "Processing molecule 4000/6467\n",
      "Processing molecule 5000/6467\n",
      "Processing molecule 6000/6467\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/5810\n",
      "Processing molecule 2000/5810\n",
      "Processing molecule 3000/5810\n",
      "Processing molecule 4000/5810\n",
      "Processing molecule 5000/5810\n",
      "Data created!!\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/6774\n",
      "Processing molecule 2000/6774\n",
      "Processing molecule 3000/6774\n",
      "Processing molecule 4000/6774\n",
      "Processing molecule 5000/6774\n",
      "Processing molecule 6000/6774\n",
      "Data created!!\n"
     ]
    }
   ],
   "source": [
    "data_ds = []\n",
    "for i, task in  enumerate(tox21_tasks):\n",
    "    a = df[['smiles' , task]]\n",
    "    a = a.dropna()\n",
    "    ds = DATASET(a, smiles_to_bigraph, AttentiveFPAtomFeaturizer(), cache_file_path = cache_path)\n",
    "    data = create_dataset_with_gcn(ds, embed_class_tox21, gcn_model, tox21_tasks, i)\n",
    "    for d in data:\n",
    "        data_ds.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:1508\u001b[0m, in \u001b[0;36m_array_repr_implementation\u001b[1;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(arr\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m0\u001b[39m,):\n\u001b[1;32m-> 1508\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[43marray2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_line_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# show zero-length shape unless it is (0,)\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[], shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape),)\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:736\u001b[0m, in \u001b[0;36marray2string\u001b[1;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array2string\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:513\u001b[0m, in \u001b[0;36m_recursive_guard.<locals>.decorating_function.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m repr_running\u001b[38;5;241m.\u001b[39madd(key)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m     repr_running\u001b[38;5;241m.\u001b[39mdiscard(key)\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:539\u001b[0m, in \u001b[0;36m_array2string\u001b[1;34m(a, options, separator, prefix)\u001b[0m\n\u001b[0;32m    536\u001b[0m     summary_insert \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# find the right formatting function for the array\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m format_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_format_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# skip over \"[\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m next_line_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:472\u001b[0m, in \u001b[0;36m_get_format_function\u001b[1;34m(data, **options)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m formatdict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongfloat\u001b[39m\u001b[38;5;124m'\u001b[39m]()\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatdict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtypeobj, _nt\u001b[38;5;241m.\u001b[39mcomplexfloating):\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtypeobj, _nt\u001b[38;5;241m.\u001b[39mclongfloat):\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:411\u001b[0m, in \u001b[0;36m_get_formatdict.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_formatdict\u001b[39m(data, \u001b[38;5;241m*\u001b[39m, precision, floatmode, suppress, sign, legacy,\n\u001b[0;32m    404\u001b[0m                     formatter, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# note: extra arguments in kwargs are ignored\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \n\u001b[0;32m    407\u001b[0m     \u001b[38;5;66;03m# wrapped in lambdas to avoid taking a code path with the wrong type of data\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     formatdict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: BoolFormat(data),\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: IntegerFormat(data),\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mFloatingFormat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloatmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegacy\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: FloatingFormat(\n\u001b[0;32m    414\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplexfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[0;32m    416\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongcomplexfloat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[0;32m    418\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: DatetimeFormat(data, legacy\u001b[38;5;241m=\u001b[39mlegacy),\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimedelta\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: TimedeltaFormat(data),\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: _object_format,\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: str_format,\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpystr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: repr_format}\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# we need to wrap values in `formatter` in a lambda, so that the interface\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# is the same as the above values.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindirect\u001b[39m(x):\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:932\u001b[0m, in \u001b[0;36mFloatingFormat.__init__\u001b[1;34m(self, data, precision, floatmode, suppress_small, sign, legacy)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlarge_exponent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillFormat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:939\u001b[0m, in \u001b[0;36mFloatingFormat.fillFormat\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    936\u001b[0m finite_vals \u001b[38;5;241m=\u001b[39m data[isfinite(data)]\n\u001b[0;32m    938\u001b[0m \u001b[38;5;66;03m# choose exponential mode based on the non-zero finite values:\u001b[39;00m\n\u001b[1;32m--> 939\u001b[0m abs_non_zero \u001b[38;5;241m=\u001b[39m \u001b[43mabsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinite_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfinite_vals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(abs_non_zero) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    941\u001b[0m     max_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(abs_non_zero)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(data_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "9wZRIKrq2Kec",
    "outputId": "6a5e45aa-32cb-47da-d25c-325f6cfe106b",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 91\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSave_model!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result , best_model\n\u001b[1;32m---> 91\u001b[0m scores, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(df, k, shuffle)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(df):\n\u001b[0;32m     15\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m [df[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_index] \n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     valid_ds \u001b[38;5;241m=\u001b[39m [df[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m test_index]\n\u001b[0;32m     20\u001b[0m     label_pos , label_neg, _ , _ \u001b[38;5;241m=\u001b[39m count_lablel(train_ds)\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    429\u001b[0m     )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    663\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    593\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    594\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    598\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor_str.py:347\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mc:\\Users\\stdso\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor_str.py:129\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 129\u001b[0m     tensor_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloating_dtype:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m tensor_view:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "Epoch_S = 10\n",
    "\n",
    "def evaluate_model(df, k = 10 , shuffle = False):\n",
    "    \n",
    "    result =[] \n",
    "    s = 0\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle= shuffle, random_state=None)\n",
    "    \n",
    "    for train_index, test_index in kf.split(df):\n",
    "\n",
    "        train_ds = [df[index] for index in train_index] \n",
    "        print(train_ds)\n",
    "        \n",
    "        valid_ds = [df[index] for index in test_index]\n",
    "        \n",
    "        label_pos , label_neg, _ , _ = count_lablel(train_ds)\n",
    "        print(f'train positive label: {label_pos} - train negative label: {label_neg}')\n",
    "        \n",
    "        train_ds = up_and_down_Samplenig(train_ds, scale_downsampling = 0.5)\n",
    "        \n",
    "        label_pos , label_neg , _ , _ = count_lablel(train_ds)\n",
    "        print(f'up and down sampling => train positive label: {label_pos} - train negative label: {label_neg}')\n",
    "\n",
    "        label_pos , label_neg, _ , _ = count_lablel(valid_ds)\n",
    "        print(f'Test positive label: {label_pos} - Test negative label: {label_neg}')\n",
    "\n",
    "        l_train = []\n",
    "        r_train = []\n",
    "        lbls_train = []\n",
    "        l_valid = []\n",
    "        r_valid = []\n",
    "        lbls_valid = []\n",
    "\n",
    "        for i , data in enumerate(train_ds):\n",
    "            embbed_drug, onehot_task, embbed_task, lbl, task_number, task_name = data\n",
    "            l_train.append(embbed_drug[0])\n",
    "            r_train.append(embbed_task)\n",
    "            lbls_train.append(lbl.tolist())\n",
    "        \n",
    "        for i , data in enumerate(valid_ds):\n",
    "            embbed_drug, onehot_task, embbed_task, lbl, task_number, task_name = data\n",
    "            l_valid.append(embbed_drug[0])\n",
    "            r_valid.append(embbed_task)\n",
    "            lbls_valid.append(lbl.tolist())\n",
    "\n",
    "        l_train = np.array(l_train).reshape(-1,512,1)\n",
    "        r_train = np.array(r_train).reshape(-1,512,1)\n",
    "        lbls_train = np.array(lbls_train)\n",
    "\n",
    "        l_valid = np.array(l_valid).reshape(-1,512,1)\n",
    "        r_valid = np.array(r_valid).reshape(-1,512,1)\n",
    "        lbls_valid = np.array(lbls_valid)\n",
    "\n",
    "        # create neural network model\n",
    "        siamese_net = siamese_model_attentiveFp_tox21()\n",
    "        \n",
    "        history = History()\n",
    "        P = siamese_net.fit([l_train, r_train], lbls_train, epochs = Epoch_S, batch_size = 128, callbacks=[history])\n",
    "\n",
    "        for j in range(100):\n",
    "            C=1\n",
    "            Before = int(P.history['accuracy'][-1]*100)\n",
    "            for i in range(2,Epoch_S+1):\n",
    "                if  int(P.history['accuracy'][-i]*100) == Before:\n",
    "                    C=C+1\n",
    "                else:\n",
    "                    C=1\n",
    "                Before=int(P.history['accuracy'][-i]*100)\n",
    "                print(Before)\n",
    "            if C==Epoch_S:\n",
    "                break\n",
    "            P = siamese_net.fit([l_train, r_train], lbls_train, epochs = Epoch_S, batch_size = 128, callbacks=[history])\n",
    "        print(j+1)\n",
    "        \n",
    "        score  = siamese_net.evaluate([l_valid,r_valid], lbls_valid, verbose=1)\n",
    "        a = (score[1],score[4])\n",
    "        result.append(a)\n",
    "        \n",
    "        if score[4] > s :\n",
    "            best_model = siamese_net\n",
    "            s = score[4]\n",
    "            print(\"Save_model!!\")\n",
    "    \n",
    "    return result , best_model\n",
    "\n",
    "\n",
    "scores, best_model = evaluate_model(data_ds, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dropout = 0.3 and downsampling = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "auc = []\n",
    "for i in scores:\n",
    "    acc.append(i[0])\n",
    "    auc.append(i[1])\n",
    "\n",
    "print(f'accuracy= {np.mean(acc)} AUC= {np.mean(auc)} STD_AUC= {np.std(auc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dropout = 0.2 and downsampling = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "auc = []\n",
    "for i in scores:\n",
    "    acc.append(i[0])\n",
    "    auc.append(i[1])\n",
    "\n",
    "print(f'accuracy= {np.mean(acc)} AUC= {np.mean(auc)} STD_AUC= {np.std(auc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "_dyrk9nGcM81"
   },
   "source": [
    "# Classification with BioAct-Het and Canonical GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "UePCH8kkoBE5",
    "outputId": "9a7ab5d3-9594-44f5-bddb-d47a6c996228"
   },
   "outputs": [],
   "source": [
    "model_GCN = 'GCN_canonical_Tox21'\n",
    "gcn_model = get_tox21_model(model_GCN)\n",
    "gcn_model.eval()\n",
    "gcn_model = gcn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ds = []\n",
    "for i, task in  enumerate(tox21_tasks):\n",
    "    a = df[['smiles' , task]]\n",
    "    a = a.dropna()\n",
    "    ds =  DATASET(a, smiles_to_bigraph, CanonicalAtomFeaturizer(), cache_file_path = cache_path)\n",
    "    data = create_dataset_with_gcn(ds, embed_class_tox21, gcn_model, tox21_tasks, i)\n",
    "    for d in data:\n",
    "        data_ds.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "hidden": true,
    "id": "rEpMXuj7ndA7",
    "outputId": "7d6726e0-4792-4d06-953e-648851f6117a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "Epoch_S = 10\n",
    "\n",
    "def evaluate_model(df, k = 10 , shuffle = False):\n",
    "    result =[]    \n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle= shuffle, random_state=None)\n",
    "    \n",
    "    for train_index, test_index in kf.split(df):\n",
    "\n",
    "        train_ds = [df[index] for index in train_index] \n",
    "        \n",
    "        valid_ds = [df[index] for index in test_index]\n",
    "        \n",
    "        label_pos , label_neg, _, _ = count_lablel(train_ds)\n",
    "        print(f'train positive label: {label_pos} - train negative label: {label_neg}')\n",
    "        \n",
    "        train_ds = up_and_down_Samplenig(train_ds, scale_downsampling = 0.5)\n",
    "        \n",
    "        label_pos , label_neg , _,_ = count_lablel(train_ds)\n",
    "        print(f'up and down sampling => train positive label: {label_pos} - train negative label: {label_neg}')\n",
    "\n",
    "        label_pos , label_neg, _,_ = count_lablel(valid_ds)\n",
    "        print(f'Test positive label: {label_pos} - Test negative label: {label_neg}')\n",
    "\n",
    "        l_train = []\n",
    "        r_train = []\n",
    "        lbls_train = []\n",
    "        l_valid = []\n",
    "        r_valid = []\n",
    "        lbls_valid = []\n",
    "\n",
    "        for i , data in enumerate(train_ds):\n",
    "            embbed_drug, onehot_task, embbed_task, lbl, task_name = data\n",
    "            l_train.append(embbed_drug[0])\n",
    "            r_train.append(embbed_task)\n",
    "            lbls_train.append(lbl.tolist())\n",
    "        \n",
    "        for i , data in enumerate(valid_ds):\n",
    "            embbed_drug, onehot_task, embbed_task, lbl, task_name = data\n",
    "            l_valid.append(embbed_drug[0])\n",
    "            r_valid.append(embbed_task)\n",
    "            lbls_valid.append(lbl.tolist())\n",
    "\n",
    "        l_train = np.array(l_train).reshape(-1,128,1)\n",
    "        r_train = np.array(r_train).reshape(-1,512,1)\n",
    "        lbls_train = np.array(lbls_train)\n",
    "\n",
    "        l_valid = np.array(l_valid).reshape(-1,128,1)\n",
    "        r_valid = np.array(r_valid).reshape(-1,512,1)\n",
    "        lbls_valid = np.array(lbls_valid)\n",
    "\n",
    "        # create neural network model\n",
    "        siamese_net = siamese_model_Canonical_tox21()\n",
    "        history = History()\n",
    "        P = siamese_net.fit([l_train, r_train], lbls_train, epochs = Epoch_S, batch_size = 128, callbacks=[history])\n",
    "\n",
    "        for j in range(100):\n",
    "            C=1\n",
    "            Before = int(P.history['accuracy'][-1]*100)\n",
    "            for i in range(2,Epoch_S+1):\n",
    "                if  int(P.history['accuracy'][-i]*100) == Before:\n",
    "                    C=C+1\n",
    "                else:\n",
    "                    C=1\n",
    "                Before=int(P.history['accuracy'][-i]*100)\n",
    "                print(Before)\n",
    "            if C==Epoch_S:\n",
    "                break\n",
    "            P = siamese_net.fit([l_train, r_train], lbls_train, epochs = Epoch_S, batch_size = 128, callbacks=[history])\n",
    "        print(j+1)\n",
    "        \n",
    "        score  = siamese_net.evaluate([l_valid,r_valid], lbls_valid, verbose=1)\n",
    "        a = (score[1],score[4])\n",
    "        result.append(a)\n",
    "    \n",
    "    return result\n",
    "\n",
    "scores = evaluate_model(data_ds, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "#### Dropout = 0.3 and downsampling = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "auc = []\n",
    "for i in scores:\n",
    "    acc.append(i[0])\n",
    "    auc.append(i[1])\n",
    "\n",
    "print(f'accuracy= {np.mean(acc)} AUC= {np.mean(auc)} STD_AUC= {np.std(auc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dropout = 0.2 and downsampling = 0.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "auc = []\n",
    "for i in scores:\n",
    "    acc.append(i[0])\n",
    "    auc.append(i[1])\n",
    "\n",
    "print(f'accuracy= {np.mean(acc)} AUC= {np.mean(auc)} STD_AUC= {np.std(auc)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zIKQi__XAcia"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
